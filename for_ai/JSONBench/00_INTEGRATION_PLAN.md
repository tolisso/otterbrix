# План интеграции Otterbrix в JSONBench

## Обзор

JSONBench — это открытый бенчмарк для сравнения производительности аналитических баз данных при работе с JSON данными. Интеграция Otterbrix в JSONBench позволит продемонстрировать производительность Otterbrix на реальных JSON-данных (1 миллиард событий Bluesky) и сравнить его с другими системами (ClickHouse, DuckDB, PostgreSQL, MongoDB, Elasticsearch и др.).

## Цели интеграции

1. **Демонстрация производительности**: Показать возможности Otterbrix при работе с большими объемами JSON данных
2. **Прозрачное сравнение**: Обеспечить объективное сравнение с другими системами в соответствии с принципами JSONBench
3. **Валидация архитектуры**: Проверить эффективность гибридной модели хранения Otterbrix на реальных данных
4. **Маркетинг**: Создать публичную демонстрацию возможностей Otterbrix

## Структура JSONBench

JSONBench организован следующим образом:
```
JSONBench/
├── download_data.sh              # Скачивание датасета
├── generate-results.sh           # Генерация результатов
├── index.html                    # Веб-интерфейс с результатами
└── <database_name>/              # Директория для каждой БД
    ├── main.sh                   # Главный скрипт запуска
    ├── install.sh                # Установка БД
    ├── uninstall.sh              # Удаление БД
    ├── create_and_load.sh        # Создание таблиц и загрузка данных
    ├── load_data.sh              # Загрузка данных
    ├── ddl.sql                   # DDL для создания таблиц
    ├── queries.sql               # Запросы для бенчмарка
    ├── queries_formatted.sql     # Запросы с форматированием
    ├── benchmark.sh              # Запуск бенчмарка
    ├── run_queries.sh            # Выполнение запросов с таймингом
    ├── count.sh                  # Подсчет строк
    ├── total_size.sh             # Размер данных
    ├── data_size.sh              # Размер данных (альтернатива)
    ├── index_size.sh             # Размер индексов
    ├── index_usage.sh            # Использование индексов
    ├── physical_query_plans.sh   # Планы запросов
    ├── query_results.sh          # Результаты запросов
    ├── drop_table.sh             # Удаление таблиц
    └── results/                  # JSON с результатами бенчмарков
        ├── <machine>_bluesky_1m.json
        ├── <machine>_bluesky_10m.json
        ├── <machine>_bluesky_100m.json
        └── <machine>_bluesky_1000m.json
```

## Датасет

- **Источник**: События Bluesky, собранные через Jetstream
- **Формат**: NDJSON (newline-delimited JSON), сжатые в .json.gz
- **Размеры**: 1M, 10M, 100M, 1000M записей
- **Объем**: 125 GB сжатый, 425 GB несжатый (для 1B записей)
- **Структура данных**: События с вложенной структурой (did, kind, commit, time_us и т.д.)

Пример структуры события:
```json
{
  "did": "did:plc:...",
  "kind": "commit",
  "time_us": 1234567890123456,
  "commit": {
    "collection": "app.bsky.feed.post",
    "operation": "create",
    ...
  }
}
```

## Бенчмарк-запросы

JSONBench включает 5 аналитических запросов:

1. **Q1**: Группировка по типу события с подсчетом
2. **Q2**: Группировка по типу события с подсчетом пользователей (DISTINCT)
3. **Q3**: Группировка по типу события и часу дня с фильтрацией
4. **Q4**: Поиск первых пользователей с ORDER BY и LIMIT
5. **Q5**: Вычисление временного промежутка активности пользователей

Каждый запрос выполняется 3 раза (cold run + 2 hot runs) для получения стабильных результатов.

## План работ

### Этап 1: Подготовка инфраструктуры (1-2 дня)

1. **Создание директории `otterbrix/` в JSONBench**
   - Скопировать структуру из существующего примера (например, duckdb)
   - Адаптировать под Otterbrix

2. **Настройка окружения**
   - Определить способ установки Otterbrix (pip install, docker, сборка из исходников)
   - Подготовить скрипт установки

### Этап 2: Реализация скриптов (3-5 дней)

#### 2.1. install.sh и uninstall.sh
- Установка Python-пакета otterbrix
- Установка зависимостей
- Проверка успешности установки

#### 2.2. ddl.sql
- Создание базы данных
- Создание коллекции/таблицы для JSON
- Определение индексов (если поддерживается)

#### 2.3. load_data.sh
- Чтение .json.gz файлов
- Парсинг NDJSON
- Вставка данных через Python API
- Обработка ошибок

#### 2.4. queries.sql
- Перевод 5 стандартных запросов на SQL-диалект Otterbrix
- Учет особенностей работы с JSON
- Тестирование корректности результатов

#### 2.5. run_queries.sh и benchmark.sh
- Выполнение запросов с измерением времени
- Очистка кеша между запросами
- Логирование результатов

#### 2.6. Метрики (total_size.sh, count.sh и т.д.)
- Подсчет размера данных
- Подсчет записей
- Сбор статистики

#### 2.7. main.sh
- Оркестрация всего процесса
- Поддержка разных размеров датасета
- Обработка ошибок и логирование

### Этап 3: Тестирование (2-3 дня)

1. **Тестирование на малых данных (1M)**
   - Проверка корректности загрузки
   - Проверка корректности результатов запросов
   - Отладка проблем

2. **Тестирование на средних данных (10M, 100M)**
   - Проверка производительности
   - Проверка стабильности
   - Оптимизация

3. **Полный запуск (1000M)**
   - На машине типа m6i.8xlarge
   - Полный цикл бенчмарка
   - Сбор всех метрик

### Этап 4: Документирование результатов (1 день)

1. **Создание JSON-файлов с результатами**
   - Формат соответствует другим БД
   - Результаты для всех размеров датасета

2. **Документирование особенностей**
   - README в директории otterbrix/
   - Описание настроек
   - Известные ограничения

3. **Создание PR в JSONBench**
   - Соответствие принципам бенчмарка
   - Документирование изменений

### Этап 5: Оптимизация (опционально, 2-3 дня)

1. **Анализ узких мест**
   - Профилирование запросов
   - Анализ планов выполнения

2. **Оптимизация**
   - Создание индексов
   - Настройка параметров
   - Оптимизация запросов

## Технические вызовы

### 1. Python API vs CLI
- Большинство БД в JSONBench используют CLI
- Otterbrix имеет Python API
- Решение: обертка или Python-скрипт для загрузки/запросов

### 2. Загрузка данных
- Нужно эффективно загрузить до 1B записей
- Batch-вставки vs построчная загрузка
- Управление памятью

### 3. SQL-диалект
- Перевод запросов на SQL-диалект Otterbrix
- Работа с JSON-путями
- Функции для работы с датой/временем

### 4. Производительность
- Оптимизация для аналитических запросов
- Использование индексов
- Управление кешем

### 5. Метрики
- Получение размера БД
- Получение статистики использования
- Планы выполнения запросов

## Критерии успеха

1. **Функциональность**
   - ✅ Успешная загрузка всех размеров датасета
   - ✅ Корректные результаты всех 5 запросов
   - ✅ Стабильная работа без падений

2. **Производительность**
   - ✅ Сравнимая с DuckDB производительность на структурированных частях
   - ✅ Преимущество на сложных вложенных структурах
   - ✅ Эффективное использование памяти

3. **Воспроизводимость**
   - ✅ Автоматический запуск всех тестов
   - ✅ Четкая документация
   - ✅ Соответствие принципам JSONBench

4. **Интеграция**
   - ✅ PR принят в репозиторий JSONBench
   - ✅ Результаты отображаются на https://clickhouse.com/json-bench
   - ✅ Документация обновлена

## Риски и митигация

| Риск | Вероятность | Влияние | Митигация |
|------|-------------|---------|-----------|
| Otterbrix не поддерживает нужные SQL-функции | Средняя | Высокое | Ранняя проверка SQL-диалекта, возможная адаптация запросов |
| Низкая производительность на больших данных | Средняя | Высокое | Профилирование, оптимизация, использование индексов |
| Проблемы со стабильностью при 1B записей | Низкая | Высокое | Тщательное тестирование на меньших объемах, обработка ошибок |
| Долгое время загрузки данных | Высокая | Среднее | Batch-вставки, оптимизация I/O |
| Несовместимость с требованиями JSONBench | Низкая | Среднее | Соблюдение принципов, консультации с мейнтейнерами |

## Ресурсы

### Необходимое оборудование
- **Разработка/тестирование**: Локальная машина с 16GB+ RAM
- **Полный бенчмарк**: AWS m6i.8xlarge (32 vCPU, 128GB RAM, 10TB gp3)

### Время
- **Разработка**: 7-12 дней
- **Тестирование**: 2-3 дня
- **Бенчмарк (1B)**: 1-2 дня выполнения

### Команда
- **Разработчик Otterbrix**: Знание архитектуры, SQL-диалекта
- **DevOps**: Настройка окружения, управление тестовыми машинами

## Следующие шаги

1. ✅ Создать план интеграции (этот документ)
2. ⏭️ Изучить SQL-диалект Otterbrix и возможности работы с JSON
3. ⏭️ Создать прототип загрузки данных на малой выборке (1000 записей)
4. ⏭️ Реализовать все 5 запросов и проверить результаты
5. ⏭️ Создать полную структуру скриптов
6. ⏭️ Протестировать на 1M записей
7. ⏭️ Масштабировать на 10M, 100M
8. ⏭️ Провести полный бенчмарк на 1B
9. ⏭️ Создать PR в JSONBench

## Справка

- **JSONBench GitHub**: https://github.com/ClickHouse/JSONBench
- **JSONBench Blog**: https://clickhouse.com/blog/json-bench-clickhouse-vs-mongodb-elasticsearch-duckdb-postgresql
- **JSONBench Dashboard**: https://clickhouse.com/json-bench
- **Otterbrix GitHub**: https://github.com/agdev/otterbrix
- **Otterbrix PyPI**: https://pypi.org/project/otterbrix/

